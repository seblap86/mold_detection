{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "F0NTGHv28G1S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0_dXZ3YBtiA"
      },
      "outputs": [],
      "source": [
        "# Installing opendatasets library\n",
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lwPPjJ6_WVk"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import opendatasets as od\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connecting to Google Drive"
      ],
      "metadata": {
        "id": "ec2jEdLE6kwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "MqD8NZIc6tLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset download and preprocessing"
      ],
      "metadata": {
        "id": "F6_XejiQ8TD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Downloading fruits & vegetable image recognition dataset"
      ],
      "metadata": {
        "id": "FrGRsUWS8aIC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atS0Y5d2IcaP"
      },
      "outputs": [],
      "source": [
        "# Downloading the dataset from Kaggle (requires username and key; key to be found after login in the Kaggle profile under API)\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLziBkIBBWzq"
      },
      "outputs": [],
      "source": [
        "# Setting directories for train and validation set\n",
        "train_dir = r\"/content/fruit-and-vegetable-image-recognition/train\"\n",
        "valid_dir = r'/content/fruit-and-vegetable-image-recognition/validation'\n",
        "\n",
        "# Check\n",
        "train_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup of training, validation, and test set"
      ],
      "metadata": {
        "id": "o1XYc5QL8ZDN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjqgl2GRCFbe"
      },
      "outputs": [],
      "source": [
        "# Training set setup\n",
        "training_set= tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels = 'inferred',\n",
        "    label_mode= 'categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224,224),\n",
        "    shuffle= True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset= None,\n",
        "    interpolation = \"bilinear\",\n",
        "    follow_links= False,\n",
        "    crop_to_aspect_ratio = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXPGeVm2CFj8"
      },
      "outputs": [],
      "source": [
        "# Validation set setup\n",
        "validation_set= tf.keras.utils.image_dataset_from_directory(\n",
        "    valid_dir,\n",
        "    labels = 'inferred',\n",
        "    label_mode= 'categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224,224),\n",
        "    shuffle= True, ### Shuffling\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset= None,\n",
        "    interpolation = \"bilinear\",\n",
        "    follow_links= False,\n",
        "    crop_to_aspect_ratio = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set setup\n",
        "test_set= tf.keras.utils.image_dataset_from_directory(\n",
        "    r'/content/fruit-and-vegetable-image-recognition/test',\n",
        "    labels = 'inferred',\n",
        "    label_mode= 'categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224,224),\n",
        "    shuffle= True,\n",
        "    seed=None,\n",
        "    validation_split=None,\n",
        "    subset= None,\n",
        "    interpolation = \"bilinear\",\n",
        "    follow_links= False,\n",
        "    crop_to_aspect_ratio = False\n",
        ")"
      ],
      "metadata": {
        "id": "jOmhPC28FIZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting class names before rescaling\n",
        "training_set_class_names = training_set.class_names\n",
        "validation_set_class_names = validation_set.class_names\n",
        "test_set_class_names = test_set.class_names\n",
        "\n",
        "# Check\n",
        "test_set_class_names"
      ],
      "metadata": {
        "id": "MVs6uZYrmJu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rescaling"
      ],
      "metadata": {
        "id": "2ns49_7kk0Oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check before rescaling\n",
        "for image, label in training_set.take(1):\n",
        "    print(image)"
      ],
      "metadata": {
        "id": "6UangOkmjqwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescaling\n",
        "def preprocess_rescale(image,label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    label = tf.cast(label ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "training_set = training_set.map(preprocess_rescale)\n",
        "validation_set = validation_set.map(preprocess_rescale)\n",
        "test_set = test_set.map(preprocess_rescale)"
      ],
      "metadata": {
        "id": "jhOtC1TUYvI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check after rescaling\n",
        "for image, label in training_set.take(1):\n",
        "    print(image)"
      ],
      "metadata": {
        "id": "uQxPCH_Sk3bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model setup"
      ],
      "metadata": {
        "id": "8DDU6m5t8gEP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzDbgkMTCFps"
      },
      "outputs": [],
      "source": [
        "# Defining the model (CNN - convolutional neural network)\n",
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[224,224,3])) # Loading\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten()) # Flattening\n",
        "cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dropout(0.4)) # Regularization\n",
        "cnn.add(tf.keras.layers.Dense(units=36, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPm4bbsrCFwc"
      },
      "outputs": [],
      "source": [
        "# Model summary\n",
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKqCaPuyOuv1"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "cnn.compile(loss='categorical_crossentropy' , optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001) , metrics='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and saving"
      ],
      "metadata": {
        "id": "B6p4SuD18jdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up early stopping\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5,\n",
        "                              verbose=0, mode='auto')"
      ],
      "metadata": {
        "id": "5dRKvNBmeDX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7SP1UVJO7le"
      },
      "outputs": [],
      "source": [
        "# Fitting the model (and creating history)\n",
        "history = cnn.fit(training_set,\n",
        "          validation_data = validation_set,\n",
        "          batch_size=16,\n",
        "          epochs = 3,\n",
        "          callbacks=[es]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting Google Drive path\n",
        "drive_path = '/content/gdrive/MyDrive/Data Analytics/Ironhack/Mold detection/cnn_models/'"
      ],
      "metadata": {
        "id": "PFFRdSzRmniK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and displaying history\n",
        "history_df = pd.DataFrame(history.history)\n",
        "display(history_df)\n",
        "\n",
        "history_df.to_csv(drive_path + 'history_fruit_veg_classifier.csv')"
      ],
      "metadata": {
        "id": "Kvh9qGhP9nWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving (.keras: saves the model's architecture, weights, and training configuration in a single `model.keras` zip archiv)\n",
        "cnn.save(drive_path + 'fruit_veg_classifier.keras')"
      ],
      "metadata": {
        "id": "wkpqHzyOAHkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "hb7LZvh98rx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved model or using cnn\n",
        "#loaded_model = tf.keras.models.load_model(drive_path + 'fruit_veg_classifier.keras')\n",
        "loaded_model = cnn"
      ],
      "metadata": {
        "id": "5oz-QY2qMFx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training and validation set"
      ],
      "metadata": {
        "id": "YQRgndkCFpGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizing history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Summarizing history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YPe6mX20dChK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the confusion matrix (validation_set)\n",
        "\n",
        "# Initializing variables to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterate through the validation set and make predictions\n",
        "for images, labels in validation_set:\n",
        "    true_labels.extend(np.argmax(labels, axis=1))  # Get true labels\n",
        "    predictions = loaded_model.predict(images)\n",
        "    predicted_labels.extend(np.argmax(predictions, axis=1))  # Get predicted labels\n",
        "\n",
        "# Create a classification report\n",
        "class_names = validation_set_class_names\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "plot_confusion_matrix(confusion, class_names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u0loZW8JFw8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test set - full"
      ],
      "metadata": {
        "id": "w_Mr4HH1GAWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss,test_accuracy=cnn.evaluate(test_set)"
      ],
      "metadata": {
        "id": "DQuTjvm8FhTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the confusion matrix (test_set)\n",
        "\n",
        "# Initializing variables to store true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Iterate through the test set and make predictions\n",
        "for images, labels in test_set:\n",
        "    true_labels.extend(np.argmax(labels, axis=1))  # Get true labels\n",
        "    predictions = loaded_model.predict(images)\n",
        "    predicted_labels.extend(np.argmax(predictions, axis=1))  # Get predicted labels\n",
        "\n",
        "# Create a classification report\n",
        "class_names = test_set_class_names\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "plot_confusion_matrix(confusion, class_names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KEa_REY5EupY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test set - subsample"
      ],
      "metadata": {
        "id": "3fruyb7JGMzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating predictions of a 3x3 subsample from the test dataset\n",
        "\n",
        "# Retrieve a few test samples and their corresponding true labels\n",
        "num_samples_to_display = 9\n",
        "sample_images, sample_labels = next(iter(test_set.take(num_samples_to_display)))\n",
        "\n",
        "# Get the corresponding class names from the test_set\n",
        "class_names = test_set_class_names\n",
        "\n",
        "# Make predictions on the sampled images\n",
        "sample_predictions = cnn.predict(sample_images)\n",
        "sample_predictions = np.argmax(sample_predictions, axis=1)\n",
        "\n",
        "# Displaying the images with their true and predicted labels\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10, 10),\n",
        "                         subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(sample_images[i].numpy().astype(np.uint8))\n",
        "    true_label = class_names[np.argmax(sample_labels[i])]\n",
        "    predicted_label = class_names[sample_predictions[i]]\n",
        "    ax.set_title(f\"True: {true_label}\\nPredicted: {predicted_label}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v6vDFhDfI3Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single external pictures"
      ],
      "metadata": {
        "id": "7OZebAbhGbqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing a single image\n",
        "img_path = '/content/MANDARIN.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))  # Adjusting the target size based on model's input size\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Normalizing pixel values\n",
        "\n",
        "# Predicting the class\n",
        "predictions = cnn.predict(img_array)\n",
        "\n",
        "# Getting and printing the predicted class label\n",
        "predicted_class = np.argmax(predictions)\n",
        "print()\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "\n",
        "# Displaying the name of the class\n",
        "predicted_label = class_names[np.argmax(predictions)]\n",
        "print(predicted_label)\n",
        "print()\n",
        "\n",
        "# Displaying the predicted class probabilities\n",
        "#print(\"Predicted probabilities:\", predictions)\n",
        "predictions_df = pd.DataFrame({'class': list(range(0, 36)), 'label': test_set_class_names, 'prediction (prob)': list(predictions[0])})\n",
        "predictions_df = predictions_df.sort_values(by='prediction (prob)', ascending=False)\n",
        "print(predictions_df)\n",
        "print()\n",
        "\n",
        "display(predicted_class, predicted_label)\n",
        "display(plt.imshow(img))"
      ],
      "metadata": {
        "id": "iShM0HycJTuW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}